<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Home page of Chenyu Zheng">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Chenyu Zheng</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Chenyu Zheng (郑晨宇) &nbsp;</h1></div>
        <h3>Ph.D. Student</h3>  
        <p>
            <a href="http://ai.ruc.edu.cn/" target="_blank">Gaoling School of Artificial Intelligence</a> <br>
            <a href="https://www.ruc.edu.cn/" target="_blank">Renmin University of China</a> <br>
            Email:  chenyu.zheng666[at]gmail[dot]com<br>
            Links: <a href="https://scholar.google.com/citations?user=QDfsVgYAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
                   <a href="https://github.com/Chen-yu-Zheng" target="_blank">[Github]</a>
                   <a href="https://www.zhihu.com/people/zhi-zuo-ren-23/posts" target="_blank">[Zhihu]</a>
            <!-- <a href="cv_zcy.pdf" target="_blank">[CV]</a> -->
            <br>
        </p>
    </td>

    <td><img src="./files/photo_2024.jpg" border="0" width="160"><br> </td>
</tr></tbody></table>


<h2>About me</h2>
    <p>
        I am a first-year Ph.D. student at the GSAI-ML Group, Renmin University of China, advised by Prof. <a href="https://zhenxuan00.github.io/" target="_blank">Chongxuan Li</a> fortunately.
        Before that, I received my B.E. degree from the School of Computer Science, Wuhan University in 2023. 
        <!-- I am grateful to Prof. <a href="https://sites.google.com/site/weiweiliuhomepage/" target="_blank">Weiwei Liu</a> for cultivating my theoretical foundation during my undergraduate studies. -->
    </p>

    <p> 
        The long-term goal of my research is to unveil the mystery behind the success of foundation models, and improve their efficiency and reliability.
        <!-- To this end, my research focuses on understanding the mechanisms behind the success of foundation models. -->
        Currently, I am interested in understanding the mechanisms of the remarkable abilities (e.g., in-context learning) of generative transformers (e.g., large language models).
    </p>

    <p>
        <!-- I am open for possible collaborations. Please feel free to drop me an email if there is any suitable ideas or opportunities to discuss. -->
    </p>


<h2>Selected Papers</h2>
[* indicates the equal contribution, # indicates the corresponding author]
<!-- [# indicates the corresponding author, papers are <strong>sorted by my contribution</strong>.] -->

<h3>Foundation Models Theory (2023~)</h3>

The starting point of my Ph.D. life and independent research, thanks to support from all collaborators.
<ul>
    <li>
        <paper>On Mesa-Optimization in Autoregressively Trained Transformers: Emergence and Capability</paper><br>
        <strong>Chenyu Zheng</strong>, Wei Huang, Rongzhen Wang, Guoqiang Wu, Jun Zhu, Chongxuan Li<br>
        <strong>Preprint</strong>, 2024 <br>
        <a href="https://arxiv.org/abs/2405.16845" target="_blank">[Paper]</a>
    </li>  
</ul>

<h3>Modern Machine Learning (2022~2023)</h3>

The starting point of my high-quality research, thanks my advisor <a href="https://zhenxuan00.github.io/" target="_blank">Chongxuan Li</a> for his meticulous guidance.

<ul>
    <li>
        <paper>Toward Understanding Generative Data Augmentation</paper><br>
        <strong>Chenyu Zheng</strong>, Guoqiang Wu, Chongxuan Li<br>
        Advances in Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023 <br>
        <a href="https://openreview.net/pdf?id=W5Clq1bSrR" target="_blank">[Paper]</a>
        <a href="https://github.com/ML-GSAI/Understanding-GDA" target="_blank">[Code]</a>
        <a href="files/slides/NeurIPS2023_Poster.pdf" target="_blank">[Slides]</a>
        <a href="https://mp.weixin.qq.com/s/Sil9AQJxk01mkxdxD49WGA" target="_blank">[Blog]</a>
        <a href="files/slides/NeurIPS2023_Poster.pdf" target="_blank">[Poster]</a>
    </li>        

    <li>
        <paper>Revisiting Discriminative vs. Generative Classifiers: Theory and Implications</paper><br>
        <strong>Chenyu Zheng</strong>, Guoqiang Wu, Fan Bao, Yue Cao, Chongxuan Li, Jun Zhu<br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2023 <br>
        <a href="https://proceedings.mlr.press/v202/zheng23f" target="_blank">[Paper]</a>
        <a href="https://github.com/ML-GSAI/Revisiting-Dis-vs-Gen-Classifiers" target="_blank">[Code]</a>
        <a href="files/slides/ICML2023_slides.pdf" target="_blank">[Slides]</a>
        <a href="https://zhuanlan.zhihu.com/p/641042101" target="_blank">[Blog]</a>
        <a href="files/slides/ICML2023_Poster.pdf" target="_blank">[Poster]</a>
    </li>        
</ul>

<h3>Remote Sensing (2021~2022)</h3>
The starting point of my research career, thanks Ph.D. <a href="http://junjuewang.top/" target="_blank">Junjue Wang</a> for his friendly and patient guidance.
<ul>
    <li>
        <paper>Domain Adaptive Land-Cover Classification via Local Consistency and Global Diversity</paper><br>
        Ailong Ma, <strong>Chenyu Zheng#</strong>, Junjue Wang, Yanfei Zhong<br>
        IEEE Transactions on Geoscience and Remote Sensing <strong>(TGRS)</strong>, 2023 <br>
        <a href="https://ieeexplore.ieee.org/document/10094018" target="_blank">[Paper]</a>
        <a href="https://github.com/Chen-yu-Zheng/LCGDM" target="_blank">[Code]</a>
    </li>
</ul>

<h2>Experience</h2>
    <ul>
        <li>
            <p>
                <b>Research Intern</b>, <a href="https://www.antgroup.com/" target="_blank"> Ant Group</a>, Beijing, China (2023.10 - Present) </br>
                <!-- Mentor: Dr. Xiaolu Zhang -->
            </p>
        </li>
        <li>
            <p>
                <b>Research Intern</b>, <a href="http://rsidea.whu.edu.cn/" target="_blank"> RSIDEA Group</a>, <a href="http://www.lmars.whu.edu.cn/" target="_blank">LIESMARS</a>, Wuhan, China (2021.01 - 2022.08) </br>
                Advisors: Ph.D. candidate <a href="http://junjuewang.top/" target="_blank">Junjue Wang</a> 
                and Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=GPjZ_2gAAAAJ" target="_blank">Ailong Ma</a>
            </p>
        </li>
    </ul>

<h2>Honors</h2>
<li><strong>Outstanding Graduate & Bachelor Thesis Award</strong>, Wuhan University, 2023</li>
<li><strong>Finalist</strong>, <a href="https://www.comap.com/undergraduate/contests/index.html" target="_blank">International Mathematical Contest in Modeling (MCM)</a>, 2022</li>
<li><strong>China National Scholarship</strong>, Ministry of Education of China, 2020</li>

<h2>Academic Services</h2>

<h3>Conference Reviewer</h3>
Advances in Neural Information Processing Systems (NeurIPS): 2024

<h3>Workshop Reviewer</h3>
ICLR Workshop on Bridging the Gap Between Practice and Theory in Deep Learning (ICLR-BGPT): 2024

<h2>Tutorials/Talks</h2>
<li><strong>Tutorial: A Brief Review of In-Context Learning Theory</strong>, 2024.05 <a href="files/slides/ICL_slides.pdf" target="_blank">[Slides]</a></li>
<li><strong>Tutorial: Classical Machine Learning Theory</strong>, 2023.06 <a href="files/slides/Classical_learning_theory_slides.pdf" target="_blank">[Slides]</a></li>

<h2>Miscellaneous</h2>
<li> <a href="https://en.wikipedia.org/wiki/Platform_Sutra" target="_blank">Platform Sutra</a> and meditation teach me a lot.
<a href="https://www.bilibili.com/video/BV1uZ4y1D787" target="_blank">[Platform Sutra viedo]</a>
<a href="https://www.bilibili.com/video/BV1Rq4y1F7r4" target="_blank">[meditation viedo]</a></li>

</div>


<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2024.05 Chenyu Zheng

<br>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=304&t=tt&d=QKzhOFC4Zd4B3RPDevM29Z3rS_DmIkoOSxyHMcDJogo'></script>

</body>

</html>
